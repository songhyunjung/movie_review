# 📚 한국어 영화 리뷰 감성 분석 프로젝트 (NSMC)

---

## 1. 프로젝트 개요

이 프로젝트는 네이버 영화 리뷰 데이터셋(NSMC)을 활용하여 **한국어 영화 리뷰의 긍정 또는 부정 감성을 분류하는 머신러닝 모델을 구축**하고 평가하는 것을 목표로 합니다. 자연어 처리(NLP)의 기본 파이프라인을 이해하고, 실제 텍스트 데이터를 전처리하여 머신러닝 모델에 적용하는 과정을 경험하기 위해 기획되었습니다.

## 2. 사용 데이터셋

* **데이터셋 명칭:** 네이버 영화 리뷰 감성 분류 데이터셋 (Naver Sentiment Movie Corpus, NSMC)
* **설명:** 약 20만 개의 한국어 영화 리뷰와 해당 리뷰가 긍정(1)인지 부정(0)인지 라벨링된 데이터로 구성되어 있습니다. 훈련 데이터 (`ratings_train.txt`)와 테스트 데이터 (`ratings_test.txt`)로 분리되어 제공됩니다.
* **획득 경로:** [`e9t/nsmc GitHub Repository`](https://github.com/e9t/nsmc) 에서 `ratings_train.txt`와 `ratings_test.txt` 파일을 다운로드하여 사용했습니다.

## 3. 기술 스택

* **언어:** Python 3.x
* **주요 라이브러리:**
    * **데이터 처리:** `pandas`, `numpy`
    * **텍스트 전처리:** `re` (정규표현식)
    * **텍스트 벡터화:** `scikit-learn`의 `TfidfVectorizer`
    * **머신러닝 모델:** `scikit-learn`의 `LogisticRegression`
    * **모델 평가:** `scikit-learn.metrics` (accuracy_score, classification_report, confusion_matrix)
    * **시각화:** `matplotlib`, `seaborn` (한글 폰트 적용: `NanumBarunGothic`)
* **개발 환경:** Google Colab 또는 로컬 Jupyter Notebook

## 4. 프로젝트 진행 과정

프로젝트는 다음의 주요 단계로 진행되었습니다:

1.  **데이터 로드 및 탐색:**
    * NSMC 훈련 및 테스트 데이터셋을 `pandas` DataFrame으로 로드했습니다.
    * 데이터의 기본 정보 (`.info()`), 결측치 (`.isnull().sum()`), 중복 데이터 (`.drop_duplicates()`), 그리고 감성 라벨 분포 (`.value_counts()`)를 확인했습니다.
2.  **데이터 전처리:**
    * 결측치 및 중복된 리뷰를 제거했습니다.
    * 정규표현식(`re`)을 사용하여 리뷰 텍스트에서 한글과 공백을 제외한 모든 문자를 제거하고, 여러 공백을 단일 공백으로 처리하여 텍스트를 정제했습니다.
    * 전처리 후 길이가 0인 리뷰는 최종적으로 제거했습니다.
3.  **텍스트 벡터화 (TF-IDF):**
    * 전처리된 텍스트 데이터를 `TfidfVectorizer`를 사용하여 숫자형 벡터로 변환했습니다. `max_features`를 20000으로, `ngram_range`를 (1, 2)로 설정하여 단어 및 두 단어 조합의 중요도를 반영했습니다.
    * 훈련 데이터로 `TfidfVectorizer`를 `fit_transform`하고, 테스트 데이터에는 `transform`만 적용하여 일관된 벡터 공간을 유지했습니다.
4.  **모델 구축 및 학습:**
    * `scikit-learn`의 `LogisticRegression` 모델을 선택하여 감성 분류 모델을 구축했습니다.
    * TF-IDF 벡터화된 훈련 데이터를 사용하여 모델을 학습시켰습니다.
5.  **모델 평가:**
    * 학습된 모델을 사용하여 테스트 데이터의 감성을 예측했습니다.
    * `accuracy_score`, `classification_report` (정밀도, 재현율, F1-Score), `confusion_matrix`를 사용하여 모델의 성능을 정량적으로 평가했습니다.
6.  **결과 시각화:**
    * `matplotlib`과 `seaborn`을 활용하여 모델의 **혼동 행렬(Confusion Matrix)**을 시각화했습니다. 이를 통해 모델이 긍정과 부정을 얼마나 정확하게 분류하는지, 그리고 어떤 유형의 오류(False Positive, False Negative)를 범하는지 직관적으로 확인했습니다.

## 5. 프로젝트 결과 및 분석

프로젝트 실행 결과, 구축된 감성 분석 모델의 성능은 다음과 같습니다.

* **정확도(Accuracy):** 약 **79.10%**
* **분류 보고서 (Classification Report):**

    | 라벨 (Label) | Precision (정밀도) | Recall (재현율) | F1-Score | Support |
    | :----------: | :----------------: | :-------------: | :------: | :-----: |
    |   0 (부정)   |        0.76        |       0.85      |   0.80   |  24562  |
    |   1 (긍정)   |        0.83        |       0.74      |   0.78   |  24868  |
    | **Weighted Avg** |        **0.80** |       **0.79** |   **0.79** |  **49430** |

* **혼동 행렬 (Confusion Matrix):**
    ```
    [[20811  3751]
     [ 6578 18290]]
    ```
    * **True Negative (TN):** 20,811개 (실제 부정 리뷰를 부정으로 정확히 예측)
    * **False Positive (FP):** 3,751개 (실제 부정 리뷰를 긍정으로 잘못 예측)
    * **False Negative (FN):** 6,578개 (실제 긍정 리뷰를 부정으로 잘못 예측)
    * **True Positive (TP):** 18,290개 (실제 긍정 리뷰를 긍정으로 정확히 예측)

---

### **주요 분석:**

모델은 약 79.10%의 **전반적인 정확도**를 달성했습니다. 분류 보고서와 혼동 행렬을 통해 세부적인 성능을 분석할 수 있습니다.

* **부정 리뷰 (라벨 0) 예측:**
    * **Recall (재현율)이 0.85**로, 실제 부정 리뷰 중에서 모델이 부정으로 잘 찾아내는 비율이 높습니다. 즉, 부정적인 리뷰를 놓치지 않고 잘 감지합니다.
    * **Precision (정밀도)이 0.76**으로, 모델이 부정이라고 예측한 리뷰 중 실제 부정인 비율은 비교적 높습니다.
* **긍정 리뷰 (라벨 1) 예측:**
    * **Precision (정밀도)이 0.83**으로, 모델이 긍정이라고 예측한 리뷰 중 실제 긍정인 비율이 높습니다.
    * **Recall (재현율)이 0.74**로, 실제 긍정 리뷰 중에서 모델이 긍정으로 잘 찾아내는 비율은 부정에 비해 상대적으로 낮습니다.

**혼동 행렬 분석:**
혼동 행렬을 보면, `FN` (실제 긍정인데 부정으로 예측, 6,578개)의 수가 `FP` (실제 부정인데 긍정으로 예측, 3,751개)보다 더 많습니다. 이는 모델이 **긍정적인 리뷰를 부정으로 잘못 판단하는 경향이 부정적인 리뷰를 긍정으로 잘못 판단하는 경향보다 강하다**는 것을 보여줍니다. 즉, 긍정적인 표현에 대해 다소 보수적이거나, 부정적인 뉘앙스가 조금이라도 포함된 긍정 리뷰를 부정으로 오인하는 경우가 있을 수 있습니다.

---

### **오류 예측 샘플 분석 (옵션: 실제 예시 포함)**

모델이 잘못 예측한 샘플들을 살펴보면, TF-IDF 기반 모델의 한계를 엿볼 수 있습니다.

* **실제는 긍정인데 부정으로 예측한 샘플 (False Negatives):**
    * "**굳**": 짧고 긍정적인 단어임에도 불구하고, 문맥이 부족하거나 학습 데이터에서 유사한 짧은 긍정 표현이 충분히 반영되지 않았을 수 있습니다.
    * "**괜찮네요오랜만포켓몬스터잼밌어요**": 긍정적인 단어들로 구성되어 있지만, 띄어쓰기가 제대로 안 된 비정형적인 문장이 전처리 과정에서 정보 손실이 있었거나, 벡터화 과정에서 충분히 긍정적으로 인식되지 않았을 가능성이 있습니다.
    * "**눈에 보이는 반전이었지만 영화의 흡인력은 사라지지 않았다**": '반전이었지만'과 같은 부정적/대립적 표현이 함께 있어, 모델이 문맥 전체의 긍정적인 의미를 파악하기 어려웠을 수 있습니다.
    * 이러한 사례들은 짧거나, 복합적이거나, 비정형적인 긍정 표현을 모델이 제대로 인식하지 못하는 경우가 있음을 시사합니다.

* **실제는 부정인데 긍정으로 예측한 샘플 (False Positives):**
    * "**은 못나올것 같다**": '못나올것 같다'는 부정적인 의미를 담고 있지만, 특정 키워드나 문맥이 충분히 부정으로 학습되지 않았거나, 긍정적인 단어가 포함되어 있을 가능성을 모델이 오인했을 수 있습니다.
    * "**뭐야라는 말 밖에는**": 감탄사 또는 질문 형태로, 특정 감성을 명확히 드러내지 않아 모델이 판단하기 어려웠을 수 있습니다.
    * 이러한 사례들은 부정적인 의미가 모호하거나, 직접적인 부정 키워드가 부족한 경우 모델이 잘못 판단할 수 있음을 보여줍니다.

이러한 분석을 통해 TF-IDF 기반 모델이 단어의 빈도와 중요도에 의존하여 감성을 분류하는 방식의 장점과 함께, 복잡한 문맥이나 미묘한 감정을 파악하는 데는 한계가 있음을 이해할 수 있습니다.

---
## 6. 결론 및 향후 계획

이 프로젝트를 통해 텍스트 데이터 전처리부터 머신러닝 모델 구축 및 평가에 이르는 자연어 처리의 기본적인 파이프라인을 성공적으로 경험했습니다. 특히, TF-IDF와 로지스틱 회귀 조합으로도 상당한 성능을 얻을 수 있음을 확인했습니다.

**향후 개선 계획:**
* 보다 복잡한 문맥이나 미묘한 감성, 비꼬는 표현 등을 파악하기 위해 **딥러닝 기반의 모델 (예: BERT 계열의 사전 학습된 모델 파인튜닝)** 적용을 고려할 수 있습니다.
* **KoNLPy**와 같은 한국어 형태소 분석기를 활용하여 단어 임베딩의 품질을 높이고 모델 성능 향상을 시도할 수 있습니다.
* 데이터 증강(Data Augmentation)이나 불균형 데이터 처리 기법을 적용하여 모델의 강건성을 높일 수 있습니다.

이 프로젝트 경험은 인공지능 대학원에서의 심화 학습과 연구에 귀중한 기초가 될 것입니다.

---
